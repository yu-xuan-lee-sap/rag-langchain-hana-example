{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of RAG using LangChain with HANA Vector DB and Generative AI Hub SDK\n",
    "This notebook shows a short example of how a RAG application could be built using LangChain, HANA Vector DB and Generative AI Hub SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Switching the current directory of the notebook to the repo root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sapmnt/home/I574161/projects/rag-langchain-hana-example/notebooks\n",
      "/sapmnt/home/I574161/projects/rag-langchain-hana-example\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "os.chdir(\"..\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "\n",
    "from hdbcli import dbapi\n",
    "from gen_ai_hub.proxy.core.proxy_clients import get_proxy_client\n",
    "from gen_ai_hub.proxy.langchain.init_models import init_embedding_model, init_llm\n",
    "from langchain_community.vectorstores import HanaDB\n",
    "from langchain_community.document_loaders import DataFrameLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading required secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"secrets/gen-ai-hub-service-key.json\", \"r\") as f:\n",
    "    gen_ai_hub_service_key = json.load(f)\n",
    "\n",
    "with open(\"secrets/hana-secrets.json\", \"r\") as f:\n",
    "    hana_secrets = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up connection to HANA DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hana_conn = dbapi.connect(\n",
    "    address=hana_secrets[\"host\"],\n",
    "    port=hana_secrets[\"port\"],\n",
    "    user=hana_secrets[\"user\"],\n",
    "    password=hana_secrets[\"password\"],\n",
    "    autocommit=True,\n",
    "    sslTrustStore=hana_secrets[\"certificate\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuring connection to Generative AI Hub\n",
    "\n",
    "**Note:** AI Core resource group might or might not be in `gen_ai_hub_service_key[\"appname\"]`, so you might need to check via AI Core API or AI Launchpad for the correct value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"AICORE_AUTH_URL\"] = gen_ai_hub_service_key[\"url\"]\n",
    "os.environ[\"AICORE_CLIENT_ID\"] = gen_ai_hub_service_key[\"clientid\"]\n",
    "os.environ[\"AICORE_CLIENT_SECRET\"] = gen_ai_hub_service_key[\"clientsecret\"]\n",
    "os.environ[\"AICORE_RESOURCE_GROUP\"] = gen_ai_hub_service_key[\"appname\"].split(\"!\")[0]\n",
    "os.environ[\"AICORE_BASE_URL\"] = f\"{gen_ai_hub_service_key['serviceurls']['AI_API_URL']}/v2\"\n",
    "\n",
    "proxy_client = get_proxy_client(\"gen-ai-hub\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying a list of models available in Generative AI Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Deployment(url='https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d1e30862f24f01ec', config_id='cb08ab6d-94d9-4534-a60e-922ec1be66ff', config_name='gemini-1.0-pro-config-1', deployment_id='d1e30862f24f01ec', model_name='gemini-1.0-pro', created_at=datetime.datetime(2024, 4, 27, 5, 34, 58, tzinfo=datetime.timezone.utc), additonal_parameters={'executable_id': 'gcp-vertexai', 'model_version': '001'}, custom_prediction_suffix=None),\n",
       " Deployment(url='https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d50f02e66f040e9f', config_id='2f34dd34-eb58-482d-a1c2-d1450011ac88', config_name='chat-bison-config-1', deployment_id='d50f02e66f040e9f', model_name='chat-bison', created_at=datetime.datetime(2024, 4, 27, 5, 34, 56, tzinfo=datetime.timezone.utc), additonal_parameters={'executable_id': 'gcp-vertexai', 'model_version': '002'}, custom_prediction_suffix=None),\n",
       " Deployment(url='https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d0644b122e3a63cb', config_id='3515d5f0-5c1d-44b2-be66-d668b78f2109', config_name='text-bison-config-1', deployment_id='d0644b122e3a63cb', model_name='text-bison', created_at=datetime.datetime(2024, 4, 27, 5, 34, 54, tzinfo=datetime.timezone.utc), additonal_parameters={'executable_id': 'gcp-vertexai', 'model_version': '002'}, custom_prediction_suffix=None),\n",
       " Deployment(url='https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/da205a2f31671f03', config_id='e8fcbcb2-f3c9-4969-90fc-34d0ee690ce5', config_name='textembedding-gecko-multilingual-config-1', deployment_id='da205a2f31671f03', model_name='textembedding-gecko-multilingual', created_at=datetime.datetime(2024, 4, 27, 5, 34, 53, tzinfo=datetime.timezone.utc), additonal_parameters={'executable_id': 'gcp-vertexai', 'model_version': '001'}, custom_prediction_suffix=None),\n",
       " Deployment(url='https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/dae0f7956991d621', config_id='e1c36ced-4ac9-45e2-83b3-875558639173', config_name='textembedding-gecko-config-1', deployment_id='dae0f7956991d621', model_name='textembedding-gecko', created_at=datetime.datetime(2024, 4, 27, 5, 34, 50, tzinfo=datetime.timezone.utc), additonal_parameters={'executable_id': 'gcp-vertexai', 'model_version': '003'}, custom_prediction_suffix=None),\n",
       " Deployment(url='https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/dabf157460dd6833', config_id='4593a9a8-4472-42cb-96e1-e9870d9780f1', config_name='gpt-35-turbo-config', deployment_id='dabf157460dd6833', model_name='gpt-35-turbo', created_at=datetime.datetime(2024, 2, 29, 6, 26, 22, tzinfo=datetime.timezone.utc), additonal_parameters={'executable_id': 'azure-openai', 'model_version': 'latest'}, custom_prediction_suffix=None),\n",
       " Deployment(url='https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d547858aeae90a04', config_id='2677de58-9fbd-4850-95a3-b2fc3b88e90f', config_name='tiiuae--falcon-40b-instruct-config', deployment_id='d547858aeae90a04', model_name='tiiuae--falcon-40b-instruct', created_at=datetime.datetime(2024, 2, 29, 6, 26, 22, tzinfo=datetime.timezone.utc), additonal_parameters={'executable_id': 'aicore-opensource', 'model_version': 'null'}, custom_prediction_suffix=None),\n",
       " Deployment(url='https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d8611c9ffc221aa6', config_id='aaab58cd-cdc0-4038-8632-fffd03ebcf37', config_name='gpt-35-turbo-16k-config', deployment_id='d8611c9ffc221aa6', model_name='gpt-35-turbo-16k', created_at=datetime.datetime(2024, 2, 29, 6, 26, 22, tzinfo=datetime.timezone.utc), additonal_parameters={'executable_id': 'azure-openai', 'model_version': 'latest'}, custom_prediction_suffix=None),\n",
       " Deployment(url='https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d0288052202782e9', config_id='61a0a107-f78a-4ea0-be2d-5720907ca198', config_name='gpt-4-32k-config', deployment_id='d0288052202782e9', model_name='gpt-4-32k', created_at=datetime.datetime(2024, 2, 29, 6, 26, 22, tzinfo=datetime.timezone.utc), additonal_parameters={'executable_id': 'azure-openai', 'model_version': '0613'}, custom_prediction_suffix=None),\n",
       " Deployment(url='https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d83cb6dfe48b13a1', config_id='9db03352-dc2e-4710-9cb7-cd224f328924', config_name='gpt-4-config', deployment_id='d83cb6dfe48b13a1', model_name='gpt-4', created_at=datetime.datetime(2024, 2, 29, 6, 26, 22, tzinfo=datetime.timezone.utc), additonal_parameters={'executable_id': 'azure-openai', 'model_version': '0613'}, custom_prediction_suffix=None),\n",
       " Deployment(url='https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d2ce114759044ddb', config_id='9094b36d-e6e7-420d-bee6-b79cabbb2eea', config_name='text-embedding-ada-002-config', deployment_id='d2ce114759044ddb', model_name='text-embedding-ada-002', created_at=datetime.datetime(2024, 2, 29, 6, 26, 22, tzinfo=datetime.timezone.utc), additonal_parameters={'executable_id': 'azure-openai', 'model_version': '2'}, custom_prediction_suffix=None)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proxy_client.deployments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining embeddings and HANA Vector DB client objects from LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = init_embedding_model(\"text-embedding-ada-002\", proxy_client=proxy_client)\n",
    "hana_vectordb = HanaDB(embedding=embeddings, connection=hana_conn, table_name=\"RAG_EXAMPLE_VECTORSTORE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data from CSV file, and writing texts and corresponding vectors to HANA DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df = pd.read_csv(\"data/rag_example_inputs.csv\")\n",
    "loader = DataFrameLoader(data_frame=input_df, page_content_column=\"text\")\n",
    "documents_to_index = loader.load()\n",
    "hana_vectordb.add_documents(documents_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building RAG chain with LangChain Expression Language (LCEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hana_vector_retriever = hana_vectordb.as_retriever()\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "setup_and_retrieval = RunnableParallel(\n",
    "    {\n",
    "        \"context\": hana_vector_retriever,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    ")\n",
    "\n",
    "llm = init_llm(\"gpt-4\", proxy_client=proxy_client)\n",
    "\n",
    "rag_chain = setup_and_retrieval | prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running RAG chain with different queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is Python typically used for?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The text does not provide specific information on what Python is typically used for.\n",
      "\n",
      "Question: What is JavaScript typically used for?\n",
      "RAG Answer: JavaScript is typically used as a core technology of the Web, alongside HTML and CSS. It is used on the client side for webpage behavior in 99% of websites. JavaScript also has application programming interfaces (APIs) for working with text, dates, regular expressions, standard data structures, and the Document Object Model (DOM).\n",
      "\n",
      "Question: Which programming languages are dynamically typed?\n",
      "RAG Answer: The programming languages that are dynamically typed are Ruby and Python.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"What is Python typically used for?\",\n",
    "    \"What is JavaScript typically used for?\",\n",
    "    \"Which programming languages are dynamically typed?\",\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"RAG Answer: {rag_chain.invoke(question)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-langchain-hana-example-L_RdtZ1Y-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
